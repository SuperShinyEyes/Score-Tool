import dash_html_components as html
import base64
image_filename = './dissertation/pulkkis_sm.png' # Picture of me
encoded_image2 = base64.b64encode(open(image_filename, 'rb').read())
def aboutText():
    text = html.Div(children=[html.Img(src='data:image/png;base64,{}'.format(encoded_image2.decode()),
                                style={'width': '20vw', 'display': 'inline', 'float': 'left'}),html.Div(children='''
I am a classical composer with work catalogue of over 50 works. Most of my works are composed for symphony orchestra with or without a soloist. I did my masters studies at Sibelius Academy, but studied also mathematics and computer science at Helsinki University. Even in my early orchestral works I tried to find algorithms to combine instrument sounds as a full-sounding spectrum. In 2018 I started my doctoral studies at Sibelius Academy in order to research possibilities of algorithmic help in orchestration practice.
The motivation to start my research came from situations I encountered several times at the orchestra rehearsals: An inaudible solo instrument, i.e. the desired solo instrument, which I call target, is masked by the surrounding orchestration. The most popular orchestration study books, such as Piston and Adler, concentrate mainly on teaching how to combine instruments and how to orchestrate for certain effect, but very little about the audibility of the target. For example Samuel Adler has only two mentions on the subject: The piano sound cannot be masked by the orchestra, and an example from Beethovenâ€™s violin concerto where violin is masked by the orchestra. 
The masking problem is a frequent topic with fellow composers. The most common solution is to give room in register for the target. This solution often fails, as loud instruments mask sounds several octaves above them, and more than an octave below. Contemporary music contains often complex and rapidly changing texture, so recognizing the problem from the score and fixing it can be a difficult task. I have several personal experiences of unintended masking of the target at orchestral rehearsals, but the limited rehearsal time makes it impossible to fix the situation otherwise than asking everybody else but the target to play at lower dynamics. However, lowering dynamics may lead to unsatisfying artistic choices.
There has been vey little previous research about the masking effects in orchestration. There are, however, good dissertations and articles about the nearby subject: Blending. U.S. scholars Sandell and Lembke have both done research on blending and introduced factors in orchestration determining the blend. Christoph Reuter from Vienna University have done some interesting listening experiments on how the audibility of formant areas affects the instrument discrimination. On top of the cake there is an Ircam software, which does the opposite that I want, i.e. finds an orchestration for user input sound.
''', style={'display': 'inline', 'fontSize':24})])
    return text